{"version":3,"file":"js/app.e86c135e.js","mappings":"gGAAIA,EAAS,WAAkB,IAAIC,EAAIC,KAAQD,EAAIE,MAAMC,GAAG,OAAOH,EAAII,GAAG,EAC1E,EACIC,EAAkB,CAAC,WAAY,IAAIL,EAAIC,KAAKE,EAAGH,EAAIE,MAAMC,GAAG,OAAOA,EAAG,MAAM,CAACG,MAAM,CAAC,GAAK,QAAQ,CAACH,EAAG,UAAU,CAACI,YAAY,wCAAwC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,MAAM,CAACI,YAAY,oBAAoB,CAACJ,EAAG,MAAM,CAACI,YAAY,gBAAgB,CAACJ,EAAG,IAAI,CAACI,YAAY,eAAe,CAACJ,EAAG,MAAM,CAACG,MAAM,CAAC,IAAME,EAAQ,MAAiC,IAAM,YAAYL,EAAG,OAAO,CAACI,YAAY,gBAAgBD,MAAM,CAAC,cAAc,oBAAoB,CAACH,EAAG,QAAQA,EAAG,QAAQA,EAAG,YAAYA,EAAG,MAAM,CAACI,YAAY,cAAcD,MAAM,CAAC,GAAK,oBAAoB,CAACH,EAAG,MAAM,CAACI,YAAY,cAAc,CAACJ,EAAG,IAAI,CAACI,YAAY,eAAe,CAACP,EAAIS,GAAG,YAAYN,EAAG,IAAI,CAACI,YAAY,eAAe,CAACP,EAAIS,GAAG,gBAAgBN,EAAG,IAAI,CAACI,YAAY,cAAcD,MAAM,CAAC,KAAO,kFAAkF,CAACN,EAAIS,GAAG,aAAaN,EAAG,OAAO,CAACI,YAAY,eAAe,CAACJ,EAAG,IAAI,CAACI,YAAY,4CAA4C,CAACJ,EAAG,OAAO,CAACH,EAAIS,GAAG,oCAAoCN,EAAG,MAAM,CAACI,YAAY,YAAYG,YAAY,CAAC,cAAc,OAAO,iBAAiB,SAAS,CAACP,EAAG,MAAM,CAACI,YAAY,+BAA+B,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACJ,EAAG,IAAI,CAACI,YAAY,QAAQG,YAAY,CAAC,iBAAiB,SAAS,CAACV,EAAIS,GAAG,yCAAyCN,EAAG,MAAMH,EAAIS,GAAG,4BAA4BN,EAAG,MAAM,CAACI,YAAY,UAAUJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACJ,EAAG,MAAM,CAACI,YAAY,4BAA4B,CAACJ,EAAG,MAAM,CAACI,YAAY,UAAU,CAACJ,EAAG,SAAS,CAACI,YAAY,4CAA4C,CAACP,EAAIS,GAAG,eAAeN,EAAG,MAAM,CAACI,YAAY,UAAU,CAACJ,EAAG,SAAS,CAACI,YAAY,4CAA4C,CAACJ,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,iBAAiB,CAACN,EAAIS,GAAG,uBAAuBN,EAAG,MAAM,CAACI,YAAY,UAAU,CAACJ,EAAG,SAAS,CAACI,YAAY,4CAA4C,CAACP,EAAIS,GAAG,eAAeN,EAAG,MAAM,CAACI,YAAY,UAAU,CAACJ,EAAG,SAAS,CAACI,YAAY,4CAA4C,CAACP,EAAIS,GAAG,uBAAuBN,EAAG,MAAM,CAACI,YAAY,gBAAgBJ,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,ghBAAghBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,s3BAAs3BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,4SAA4SN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,wDAAwDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,+LAA+LN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gXAAgXN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,+qBAA+qBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,22BAA22BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,6tBAA6tBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mQAAmQN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,oHAAoHN,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,KAAK,CAACA,EAAG,KAAK,CAACH,EAAIS,GAAG,qBAAqBN,EAAG,KAAK,CAACH,EAAIS,GAAG,sBAAsBN,EAAG,KAAK,CAACH,EAAIS,GAAG,6DAA6DN,EAAG,KAAK,CAACH,EAAIS,GAAG,0FAA0FN,EAAG,KAAK,CAACH,EAAIS,GAAG,mEAAmEN,EAAG,KAAK,CAACH,EAAIS,GAAG,gFAAgFN,EAAG,KAAK,CAACH,EAAIS,GAAG,8DAA8DN,EAAG,KAAK,CAACH,EAAIS,GAAG,0EAA0EN,EAAG,KAAK,CAACH,EAAIS,GAAG,mBAAmBN,EAAG,KAAK,CAACH,EAAIS,GAAG,0FAA0FN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,+QAA+QN,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,sBAAsBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gzBAAgzBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,ieAAoeN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,qzBAAqzBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mmBAAmmBN,EAAG,KAAK,CAACI,YAAY,aAAaD,MAAM,CAAC,GAAK,iBAAiB,CAACN,EAAIS,GAAG,mBAAmBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mRAAmRN,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,0BAA0BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,yLAAyLN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mUAAmUN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,irBAAmrBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,6BAA6BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,swBAAswBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,unBAAunBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,WAAWN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,wcAAwcN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,s1BAAs1BN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gbAAgbN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,8IAA8IN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gXAAgXN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,2xBAA2xBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gyBAAgyBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mnCAAmnCN,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,0BAA0BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,wuBAAwuBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,qSAAqSN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,kfAAkfN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,2FAA2FN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,6YAA6YN,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,aAAaN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,kYAAkYN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,8tBAA8tBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,eAAeN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,0qCAA0qCN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,qNAAqNN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,MAAM,CAACG,MAAM,CAAC,IAAME,EAAQ,MAA2B,IAAM,wBAAwBL,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,gSAAgSN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,ixBAAixBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,kNAAkNN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,g7BAAg7BN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,wNAAwNN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mxBAAmxBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,ovCAAovCN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,u3BAAu3BN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,i3BAAi3BN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,m2CAAm2CN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,wfAAwfN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,iwEAAiwEN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,2OAA2ON,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,mWAAmWN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,4LAA4LN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,SAAS,CAACG,MAAM,CAAC,GAAK,QAAQ,MAAQ,MAAM,OAAS,gBAAgB,YAAc,IAAI,UAAY,KAAK,IAAM,yDAAyDH,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,q/BAAq/BN,EAAG,KAAK,CAACI,YAAY,cAAc,CAACP,EAAIS,GAAG,wBAAwBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,2nBAA2nBN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,uEAAuEN,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,uZAAuZN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,MAAM,CAACG,MAAM,CAAC,IAAME,EAAQ,MAA6B,IAAM,wBAAwBL,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,slBAAslBN,EAAG,UAAU,CAACI,YAAY,iCAAiC,CAACJ,EAAG,MAAM,CAACI,YAAY,aAAa,CAACJ,EAAG,MAAM,CAACG,MAAM,CAAC,IAAME,EAAQ,MAA8B,IAAM,wBAAwBL,EAAG,UAAU,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,WAAW,CAACJ,EAAG,MAAM,CAACI,YAAY,8CAA8C,CAACJ,EAAG,MAAM,CAACI,YAAY,SAAS,CAACP,EAAIS,GAAG,ifAAifN,EAAG,SAAS,CAACI,YAAY,UAAU,CAACJ,EAAG,MAAM,CAACI,YAAY,6BAA6B,CAACJ,EAAG,IAAI,CAACA,EAAG,SAAS,CAACH,EAAIS,GAAG,WAAWT,EAAIS,GAAG,QAAQN,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,uBAAuB,CAACN,EAAIS,GAAG,mBAAmBT,EAAIS,GAAG,kCAAkCN,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,mDAAmD,CAACN,EAAIS,GAAG,SAAST,EAAIS,GAAG,sCAAsCN,EAAG,IAAI,CAACG,MAAM,CAAC,KAAO,sDAAsD,CAACN,EAAIS,GAAG,qBAAqBT,EAAIS,GAAG,aACvljD,GC2mCA,GACAE,KAAAA,MACAC,WAAAA,CAEA,GClnC0O,I,UCQtOC,GAAY,OACd,EACAd,EACAM,GACA,EACA,KACA,KACA,MAIF,EAAeQ,EAAiB,QCjBhCL,EAAQ,MAERM,EAAAA,GAAAA,OAAAA,eAA2B,EAE3B,IAAIA,EAAAA,GAAI,CACNf,OAAQgB,GAAKA,EAAEC,KACdC,OAAO,O,m6GCPNC,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBE,IAAjBD,EACH,OAAOA,EAAaE,QAGrB,IAAIC,EAASN,EAAyBE,GAAY,CAGjDG,QAAS,CAAC,GAOX,OAHAE,EAAoBL,GAAUI,EAAQA,EAAOD,QAASJ,GAG/CK,EAAOD,OACf,CAGAJ,EAAoBO,EAAID,E,WCzBxB,IAAIE,EAAW,GACfR,EAAoBS,EAAI,SAASC,EAAQC,EAAUC,EAAIC,GACtD,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASC,EAAI,EAAGA,EAAIR,EAASS,OAAQD,IAAK,CACrCL,EAAWH,EAASQ,GAAG,GACvBJ,EAAKJ,EAASQ,GAAG,GACjBH,EAAWL,EAASQ,GAAG,GAE3B,IAJA,IAGIE,GAAY,EACPC,EAAI,EAAGA,EAAIR,EAASM,OAAQE,MACpB,EAAXN,GAAsBC,GAAgBD,IAAaO,OAAOC,KAAKrB,EAAoBS,GAAGa,OAAM,SAASC,GAAO,OAAOvB,EAAoBS,EAAEc,GAAKZ,EAASQ,GAAK,IAChKR,EAASa,OAAOL,IAAK,IAErBD,GAAY,EACTL,EAAWC,IAAcA,EAAeD,IAG7C,GAAGK,EAAW,CACbV,EAASgB,OAAOR,IAAK,GACrB,IAAIS,EAAIb,SACET,IAANsB,IAAiBf,EAASe,EAC/B,CACD,CACA,OAAOf,CArBP,CAJCG,EAAWA,GAAY,EACvB,IAAI,IAAIG,EAAIR,EAASS,OAAQD,EAAI,GAAKR,EAASQ,EAAI,GAAG,GAAKH,EAAUG,IAAKR,EAASQ,GAAKR,EAASQ,EAAI,GACrGR,EAASQ,GAAK,CAACL,EAAUC,EAAIC,EAwB/B,C,eC5BAb,EAAoB0B,EAAI,SAASrB,GAChC,IAAIsB,EAAStB,GAAUA,EAAOuB,WAC7B,WAAa,OAAOvB,EAAO,UAAY,EACvC,WAAa,OAAOA,CAAQ,EAE7B,OADAL,EAAoB6B,EAAEF,EAAQ,CAAEG,EAAGH,IAC5BA,CACR,C,eCNA3B,EAAoB6B,EAAI,SAASzB,EAAS2B,GACzC,IAAI,IAAIR,KAAOQ,EACX/B,EAAoBgC,EAAED,EAAYR,KAASvB,EAAoBgC,EAAE5B,EAASmB,IAC5EH,OAAOa,eAAe7B,EAASmB,EAAK,CAAEW,YAAY,EAAMC,IAAKJ,EAAWR,IAG3E,C,eCPAvB,EAAoBoC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAOvD,MAAQ,IAAIwD,SAAS,cAAb,EAGhB,CAFE,MAAOC,GACR,GAAsB,kBAAXC,OAAqB,OAAOA,MACxC,CACA,CAPuB,E,eCAxBxC,EAAoBgC,EAAI,SAASS,EAAKC,GAAQ,OAAOtB,OAAOuB,UAAUC,eAAeC,KAAKJ,EAAKC,EAAO,C,eCCtG1C,EAAoByB,EAAI,SAASrB,GACX,qBAAX0C,QAA0BA,OAAOC,aAC1C3B,OAAOa,eAAe7B,EAAS0C,OAAOC,YAAa,CAAEC,MAAO,WAE7D5B,OAAOa,eAAe7B,EAAS,aAAc,CAAE4C,OAAO,GACvD,C,eCNAhD,EAAoBiD,EAAI,G,eCKxB,IAAIC,EAAkB,CACrB,IAAK,GAaNlD,EAAoBS,EAAEU,EAAI,SAASgC,GAAW,OAAoC,IAA7BD,EAAgBC,EAAgB,EAGrF,IAAIC,EAAuB,SAASC,EAA4BC,GAC/D,IAKIrD,EAAUkD,EALVxC,EAAW2C,EAAK,GAChBC,EAAcD,EAAK,GACnBE,EAAUF,EAAK,GAGItC,EAAI,EAC3B,GAAGL,EAAS8C,MAAK,SAASC,GAAM,OAA+B,IAAxBR,EAAgBQ,EAAW,IAAI,CACrE,IAAIzD,KAAYsD,EACZvD,EAAoBgC,EAAEuB,EAAatD,KACrCD,EAAoBO,EAAEN,GAAYsD,EAAYtD,IAGhD,GAAGuD,EAAS,IAAI9C,EAAS8C,EAAQxD,EAClC,CAEA,IADGqD,GAA4BA,EAA2BC,GACrDtC,EAAIL,EAASM,OAAQD,IACzBmC,EAAUxC,EAASK,GAChBhB,EAAoBgC,EAAEkB,EAAiBC,IAAYD,EAAgBC,IACrED,EAAgBC,GAAS,KAE1BD,EAAgBC,GAAW,EAE5B,OAAOnD,EAAoBS,EAAEC,EAC9B,EAEIiD,EAAqBC,KAAK,6BAA+BA,KAAK,8BAAgC,GAClGD,EAAmBE,QAAQT,EAAqBU,KAAK,KAAM,IAC3DH,EAAmBI,KAAOX,EAAqBU,KAAK,KAAMH,EAAmBI,KAAKD,KAAKH,G,IC/CvF,IAAIK,EAAsBhE,EAAoBS,OAAEN,EAAW,CAAC,MAAM,WAAa,OAAOH,EAAoB,KAAO,IACjHgE,EAAsBhE,EAAoBS,EAAEuD,E","sources":["webpack://final_project/./src/App.vue","webpack://final_project/src/App.vue","webpack://final_project/./src/App.vue?51dd","webpack://final_project/./src/App.vue?0e40","webpack://final_project/./src/main.js","webpack://final_project/webpack/bootstrap","webpack://final_project/webpack/runtime/chunk loaded","webpack://final_project/webpack/runtime/compat get default export","webpack://final_project/webpack/runtime/define property getters","webpack://final_project/webpack/runtime/global","webpack://final_project/webpack/runtime/hasOwnProperty shorthand","webpack://final_project/webpack/runtime/make namespace object","webpack://final_project/webpack/runtime/publicPath","webpack://final_project/webpack/runtime/jsonp chunk loading","webpack://final_project/webpack/startup"],"sourcesContent":["var render = function render(){var _vm=this,_c=_vm._self._c;return _vm._m(0)\n}\nvar staticRenderFns = [function (){var _vm=this,_c=_vm._self._c;return _c('div',{attrs:{\"id\":\"app\"}},[_c('section',{staticClass:\"hero is-primary is-medium has-bg-img\"},[_c('div',{staticClass:\"hero-head\"},[_c('nav',{staticClass:\"navbar is-spaced\"},[_c('div',{staticClass:\"navbar-brand\"},[_c('a',{staticClass:\"navbar-item\"},[_c('img',{attrs:{\"src\":require(\"./assets/logo-olist-white.png\"),\"alt\":\"Logo\"}})]),_c('span',{staticClass:\"navbar-burger\",attrs:{\"data-target\":\"navbarMenuHeroA\"}},[_c('span'),_c('span'),_c('span')])]),_c('div',{staticClass:\"navbar-menu\",attrs:{\"id\":\"navbarMenuHeroA\"}},[_c('div',{staticClass:\"navbar-end\"},[_c('a',{staticClass:\"navbar-item\"},[_vm._v(\" Home \")]),_c('a',{staticClass:\"navbar-item\"},[_vm._v(\" Examples \")]),_c('a',{staticClass:\"navbar-item\",attrs:{\"href\":\"https://olist.com/pt-br/solucoes-para-comercio/vender-em-marketplaces/planos/\"}},[_vm._v(\" Plans \")]),_c('span',{staticClass:\"navbar-item\"},[_c('a',{staticClass:\"button is-primary is-inverted is-rounded\"},[_c('span',[_vm._v(\"Explainer Notebook\")])])])])])])]),_c('div',{staticClass:\"hero-body\",staticStyle:{\"padding-top\":\"5rem\",\"padding-bottom\":\"9rem\"}},[_c('div',{staticClass:\"container has-text-centered\"},[_c('div',{staticClass:\"block\"},[_c('p',{staticClass:\"title\",staticStyle:{\"padding-bottom\":\"2rem\"}},[_vm._v(\" End-to-end solutions to sell online \"),_c('br'),_vm._v(\" without a headache \")])]),_c('div',{staticClass:\"block\"}),_c('div',{staticClass:\"block\"},[_c('div',{staticClass:\"columns is-1 is-variable\"},[_c('div',{staticClass:\"column\"},[_c('button',{staticClass:\"button is-outlined is-white is-fullwidth\"},[_vm._v(\"Product\")])]),_c('div',{staticClass:\"column\"},[_c('button',{staticClass:\"button is-outlined is-white is-fullwidth\"},[_c('a',{attrs:{\"href\":\"deliveryTime\"}},[_vm._v(\"Delivery Time\")])])]),_c('div',{staticClass:\"column\"},[_c('button',{staticClass:\"button is-outlined is-white is-fullwidth\"},[_vm._v(\"Default\")])]),_c('div',{staticClass:\"column\"},[_c('button',{staticClass:\"button is-outlined is-white is-fullwidth\"},[_vm._v(\"Default\")])])])])])]),_c('div',{staticClass:\"hero-foot\"})]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Olist knows that one of the keys to growth of the platform is to have a happy customer base that can act as product ambassadors and stay on the platform while also spreading the word to new potential customers. They have therefore asked us to provide some insights on how they are doing with regards to their customers and if there is anything they can do to improve in this area. Luckily our dataset provides a good foundation for exploring this topic as we have information about the customers, reviews, geography etc. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" So, how do we actually know if the customers are happy? One of the ideal ways of knowing this, would be to perform a customer survey, asking about the customers’ satisfaction after having gone through the purchasing process. Olist, however, haven’t done this yet, so we’ll have to make use of a proxy. The best proxy, available to us, is arguably the customer reviews. It’s not as direct of a measure of customer satisfaction as a survey would have been, and one could argue that a review/rating is often more a reflection of the quality of the product than the platform. Our argument here is that a review often reflects the entire experience of a purchase – the product quality/price, delivery process, communication, and platform satisfaction. And to have happy customers Olist not only needs to ensure the quality of the platform, but every one of the aforementioned things. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" So, to begin with let’s take a look at the average reviews over time. The reviews are given as a rating from zero to five stars. We’ve excluded the months from before January 2017 in this plot as these didn’t have enough reviews to provide an accurate of estimate of the average values. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/6.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" As we can see the reviews have remained relatively steady at a value of around 4.0 to 4.3 with a small dip to around 3.7 around March 2018, but this dip has since then been recovered. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" For Olist to improve their customer satisfaction, it would be good to understand what influences it, either negatively or positively, so they can mitigate the negative factors and further improve on the positive factors. A good starting point for such an analysis is to think about what factors could affect one’s own satisfaction when making online purchases. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" If we think about what affects a customer’s satisfaction we can take on a customer journey perspective. At first the customer becomes aware of Olist. Here the branding influences the perceived quality of the experience, then the customer uses the website to search for products they want or be inspired. In this step, the quality of the website and the selection and presentation of products are the main factors. When the customer enters a specific product page it’s important that the products are presented in an accurate and descriptive way both in terms of the photos and text, to ensure that the product meets the expectations based on the presentation at the product page. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" When placing the order, the customer will of course pay for the product, here the price will influence the satisfaction both in terms of the competitiveness of the product price when compared to other websites/stores but also just in relation to the quality of the product. The estimated arrival time of the package, usually given to the customer before placing the order, will also affect whether or not the customer will actually go through with the purchase. After placing the order, until receiving the item we have the delivery time. With regards to the delivery time, two things are important. The absolute delivery time (longer delivery times are generally worse) but also the actual delivery time compared to the estimated delivery time. As a long delivery time is worse if you have been “promised” a short delivery time initially i.e. the package is delayed. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" When the order finally arrives at the customer, the state of the package is important as well as the service of the currier (Did the courier for example leave the package at the doorstep as described?) When opening and using the product, the quality and durability of the product are the main factors just as with the delivery time, we can assume that these are also perceived in two ways – both in actual terms and relative to the expectations given to the customer by the presentation on the website and the price. It’s ok to receive a cheap bike if that’s what you were expecting and you didn’t pay too much either, it’s far worse if you paid more or somehow expected to get a bargain from the presentation on the website. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Throughout the purchasing process communication is also a key factor but before, during and after the purchasing process. How good is the seller at answering inquiries? (We can’t see this directly, but maybe we can use something else as an indicator). \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" So, to recap these are the factors that we imagine could be the most influential on the customer satisfaction: \"),_c('div',{staticClass:\"content\"},[_c('ul',[_c('li',[_vm._v(\"Olist branding \")]),_c('li',[_vm._v(\"Website quality \")]),_c('li',[_vm._v(\"Production selection and overview/search functionality \")]),_c('li',[_vm._v(\"Product page accuracy and level of information – both in regards to photos and text \")]),_c('li',[_vm._v(\"Price – relative to other sellers and quality of the product \")]),_c('li',[_vm._v(\"Delivery time – both absolute and relative to the estimated delivery time \")]),_c('li',[_vm._v(\"Delivery – state of package and service level of courier\")]),_c('li',[_vm._v(\"Product quality – especially relative to expected quality and price \")]),_c('li',[_vm._v(\"Communication\")]),_c('li',[_vm._v(\"(add the customer himself, some people may be more likely to give low ratings)\")])])])]),_c('div',{staticClass:\"block\"},[_vm._v(\" This is quite a thorough list of factors that may influence the customer satisfaction. With the dataset currently available to us it’s not possible to get an insight into all of these factors, but with a bit of creativity we can get an indication of many of them. \")]),_c('h5',{staticClass:\"title is-5\"},[_vm._v(\"PRODUCT QUALITY \")]),_c('div',{staticClass:\"block\"},[_vm._v(\"Let’s start by having a look at how the product affects the ratings. We will do so by examining how much the reviews correlate with products. It’s of course worth mentioning that a correlation here, as always, does not necessitate causality. It’s possible that one product has significantly lower reviews than another product, not because of its quality, but because of other correlated factors (confounding factors). For example, a product could have a high quality and a good price, but always suffer from long delivery times and for that reason have low reviews. Another challenge here is that it’s often easier to look at the correlation between two continuous variables, or in case one is discrete, then only has a few discrete values. Here our discrete variable (product) has many possible values. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"600!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/11.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\"In the above plot we have shown the 95% confidence interval of the mean ratings of the products with more than 100 reviews. We've also renamed the products from their previous non-sensible product-IDs, to this where the first part denotes the category of the given product and the second part denotes the ranking in popularity of that product within its category. So \\\"health_beauty-1\\\", for example, would be the number one (most popular) product within \\\"Health and Beauty\\\". \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" It’s evident that there is a significant difference in the reviews given to the worst and the best products on this list as can be seen from the non-overlapping confidence intervals. It should be noted that selecting products with more than 100 reviews for this analysis in itself introduces a bias as one could expect these products’ increased popularity to be caused in part by them having a higher average rating than the average product and perhaps this is true, and the overall mean is probably skewed a bit above the average 4.09 rating of the entire population of products, not by much, however. But the important thing here is to note that there is indeed a significant difference across the rating of products, indicating that (unsurprisingly) the product has an influence on the customer’s satisfaction. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" For the rest of the analysis it would make sense to look at the other variables, such as the delivery time, while holding the products constant. That is, to look at how these other variables influences the average review score, for just one product at a time, as that would eliminate the variance coming from the product, which we can assume to be a big driver of the variance in the average reviews scores. This is, unfortunately, not possible as we don't have enough orders per product to conduct such an analysis, so we'll have to look at the effect of the other variables across all of the products. \")]),_c('h5',{staticClass:\"title is-5\",attrs:{\"id\":\"deliveryTime\"}},[_vm._v(\"Delivery Time\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Another interesting thing to look at, is how the delivery time affects the rating. We would expect a longer delivery time to have a negative impact on the rating and even more so if the informed estimated delivery time was shorter than the actual i.e. a delay occurs. \")]),_c('h6',{staticClass:\"title is-6\"},[_vm._v(\"Actual Delivery Time\")]),_c('div',{staticClass:\"block\"},[_vm._v(\"To begin with, we’ll look at how the actual delivery time is correlated with the ratings. That is, how long does it take from the item is ordered until it arrives at the customer?\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Before that, however, we’ll have a look at the distribution of the delivery times as can be seen in the below figure. It’s evident that most orders are delivered within zero to fifteen days with five to ten days being the most normal delivery time. Only very few order have delivery times longer than 40 days. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/13.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" We’ll now proceed to see how the delivery relates to the ratings, one way to do this is to look at intervals of the actual delivery time and calculate the average review score for each of these intervals. When we do this, we can see a strong correlation between these two variables, where a longer delivery time is correlated with a lower average review. The plot only shows up until delivery times of 50 days as we have excluded intervals with fewer than 500 observations to ensure that the average values are statistically significant.(The bar over the tick mark \\\"0\\\" indicates the values between 0 and 2, and the bars are colored by the number of observations in that bin). \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/19.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('h6',{staticClass:\"title is-6\"},[_vm._v(\"Estimated Delivery Time\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Another variable that may be of interest is the estimated delivery time i.e. the estimation presented to the customer when placing the order. The hypothesis here being that customers are generally more satisfied with shorter estimated delivery times. We’ll start by looking at the distribution of the estimations. Here, we see that the estimated delivery times af generally longer than the actual delivery time. This may be an indication of a deliberate policy by Olist of conservative/over-estimations, in order not to disappoint the customers with delays. A deliberate overestimation of the delivery time so to speak. This, of course has to be balanced, as overestimations that are too big would make the customer less likely to go through with the purchase. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/21.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" If we look at the relation between the delivery time estimations and the ratings as shown in the figure to the right, we can again see a negative relation, indicating that customers are generally less satisfied with longer estimations. It does not seem to affect the average values as much, however, as the actual delivery times. It’s also important to note that there is a high correlation between the actual and the estimated delivery time, so the negative correlation between the estimated delivery time and the average review, may just be because it generally also means that the actual delivery times are longer. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/90.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('h6',{staticClass:\"title is-6\"},[_vm._v(\"Delay\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" As we’ve seen so far, both the actual delivery times and estimated delivery times seem to be negatively correlated with customer satisfaction. But it’s difficult to discern whether customers are actually less satisfied when they get longer estimates or if it’s just because orders with longer estimates usually also have longer actual delivery times where the actual delivery times in that case would act as what is known as a confounding variable. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" To understand this relationship a bit better we can take a closer look at the interaction between these three variables; estimated delivery time, actual delivery time and rating. The first thing that comes to mind here is that the most important factor for customer satisfaction is actually the delay, calculated as the difference between the estimated delivery time and actual delivery time. The thinking here being that people would be more ok with a long delivery time if this is also what they expected, than if they expected a short delivery time. This thinking also follows the popular quote that happiness equals reality minus expectations. With happiness being the rating, reality being actual delivery time and expectations being the estimated delivery time. So let’s start by taking a look first at how the delays are distributed. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/29.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" As we’ve seen before the actual delivery times are generally longer than the estimated delivery times, which is also reflected by the above histogram, that shows that vast majority of orders are delivered before the estimated delivery time, resulting in the distribution of the delay having a negative mean and mode centered around -11 days – meaning that packages on average arrive around 11 days before the given estimate. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" We can also see how the delays relate to the customers rating by finding the average customer rating for each interval of delay. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/31.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" It’s quite clear that something happens once the delay is positive (the order is delayed). Packages without delays have average review scores around or a bit above the overall the average of 4.08, whereas packages with delays quickly plummet to an average rating of around 1.5 – 1.8. It seems likely that the delay here is the cause of the decrease in ratings. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Something’s that’s missing so far is the relationship between all three variables. The delay does implicitly show all three variables being the residual between estimated and actual delivery time, but a delay of 5 days, can come from an initial estimation of 10 days or 50 days. And that may make a difference in how that delay is perceived by the customer. So to further investigate this relationship we will create a heatmap showing the average rating as a function of the estimated and the actual delivery time. This plot also implicitly shows the delay, as the diagonal elements are those where the estimated delivery time equals the actual, and everything above the diagonal is negative delays (the package arrives before estimated delivery time) and below is positive delays. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"800!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/93.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" In the heatmap we can see the average review score as the color, where a high score is colored blue and a low is red. The most obvious pattern here is that everything above the diagonal (orders with a negative delay) has a much higher rating than orders below the diagonal with a positive delay. Orders towards the top left corner (when both the actual and estimated delivery times are short) also have higher ratings than orders towards the bottom right corner (when both the actual and estimated delivery times are high) in spite of these orders all being along the diagonal and hence not having a delay. So to sum up these findings, customers care a lot about whether the order is delayed, but they also care about the length of the delivery and are in general happier the shorter that is. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" If we look at the top row, with orders having an actual delivery time between 0 and 2 days, we see that customers are happier if the estimate was also low, than if the estimate was high, this is a bit surprising as one could think they would be more positively surprised when the orders actual delivery time is a lot lower than the estimated, but in fact the opposite is the case. This is good to know, as an obvious tactic would be to just overestimate the delays by far, to only have negative delays resulting in positive surprises, but this plot shows, that that’s not the best solution also becasue, as previously mentioned, this would deter some from buying. Customers are very unsatisfied with even small delays, but they are also somewhat unsatisfied with negative delays and would not buy if estimate is too long. So, the right solution is probably to provide an estimate that’s a bit on the high side as the customer satisfaction punishment is higher for a underestimate than an overestimate, but not too much on the high side as this is also punished, just not by as much. So there definitely is a sweet spot to be found. \")]),_c('h5',{staticClass:\"title is-5\"},[_vm._v(\"PRODUCT PRESENTATION\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" As previously mentioned, it can be speculated that the online presentation of the product can matter a lot for the customer satisfaction. Both for the customer experience during the buying process, but also, and perhaps more importantly, for the expectations. This is very analogous to the case just described with how delivery times affects ratings. In that analysis we saw that the actual delivery time mattered for the rating, but the delay (the difference between expectation and reality) mattered even more. The same can be speculated to be the case for the product presentation, here the expectation does not come from an estimated delivery time however, but instead from the online presentation and to some extension – the price. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" In the dataset available to us, the variables that best describe the level of description of products are the number of photos for a specific product as well as the length of the description. We’ll start by looking at how the number of photos relate to the average review scores. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/44.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" From the figure above it looks as if more photos generally are correlated with better reviews. As is always the case the causation isn’t clear. It could be that better products generally have more photos, so the difference in ratings is caused by this quality difference of the products, rather than the extra information, leading to more realistic expectations provided by the photos themselves. But looking at this figure alone, there are indications that it’s better to have more photos. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" We can also look at the same plot for the text length divided into intervals. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/49.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Again we can see a slight pattern with longer description lengths having higher average ratings. It should be noted that the plot only shows a small part of the y-axis, so even though the differences look rather large, it’s only from around 4.13 to 4.19, meaning very neglible differences compared to what we've previously seen with other variables such as the ones regarding the delivery. \")]),_c('h5',{staticClass:\"title is-5\"},[_vm._v(\"Sellers\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" We’ve previously described how things such as communication and support may be important for the customer experience. We don’t have any information on these values in the dataset, but we have some information about the sellers, that could be used as proxies or indicators of the quality of the seller that may well be correlated with the seller’s ability to serve the customers. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" We’ll start by having a look at the sellers in terms of their size (measured by the number of orders they have received) and how that size relates to average customer ratings they have received. What we can see is that there actually is a very slight negative correlation between seller size and average ratings received. But the correlation is very unclear. The main reason for this negative correlation is presumably that sellers with very few orders are more likely to only have received the most frequent review scores of 4 and 5, whereas the more experienced sellers will be more likely to also have received the less frequent lower scores, bringing them down to something closer to the global average review score. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/58.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('h5',{staticClass:\"title is-5\"},[_vm._v(\"Customers\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Another thing that may be of influence to the reviews received are the customers. Some customers may be more or less inclined to give a good or a bad review, depending on things like their personality, socio-demographic status, how they’re treated by the company etc. Presumably one of the most important things would be the personal bias i.e. that some people tend to be either more positive or negative in their reviews. If we knew the personal bias, this could be used to adjust for it, when analyzing the reviews given by a certain customer. If one customer always gave reviews between 1-4 stars for example, it could be that he perceived 4 as being a very good score and that a rating of 5 was only something to be given under very rare circumstances. Another customer may only give scores between 4 and 5, where 5 would be the standard and 4 was only if there was something specifically wrong with the item. Hence, we could introduce a personal standardized scale where the first person’s rating of 4 would be more or less equivalent to the second person’s rating of 5. This would be ideal, we can’t however do this as we only have access to one order per customer in the dataset. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" But let’s start the analysis of the customers by looking at the geographical location of our customers. We will do so using a choropleth map, where the count of orders is aggregated on a state level. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('img',{attrs:{\"src\":require(\"./assets/customers1.png\"),\"alt\":\"Italian Trulli\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" It’s evident that the vast majority of orders come from the states around São Paulo and Rio de Janeiro – the two largest cities in Brazil. Out of the 93k individual orders 62k come from the just the three states with most orders as can also be seen from the bar chart below. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/69.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" In the bar chart above the population has also been shown alongside the number of orders for each of the states. It can be seen that the most populated state São Paulo, which is also the state of Brazil’s largest city by the same name also has the highest order count when seen relative to its population size. This means that the platform is more popular (measured by orders per inhabitant) than in the other smaller states. It makes sense that more metropolitan areas are earlier adopters of a technology based platform like this, on the other hand people in more rural areas may benefit more from shopping online, with fewer shops available. On the other, other hand delivery price and time is likely higher for these people, which could also explain their smaller adoption. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" Now that we know approximately where our customers are located we can proceed to look at how our main variable of interest – the review score – is distributed geographically amongst the customers. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"500!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/71.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" We’ve now changed to a different type of geographical plot known as a hexagonal tile map. This allows us to perform our aggregations over evenly sized areas and at a smaller level than the states to also see regional differences within the states. The hexagonals does not cover all of Brazil, this is because we’ve chosen to exclude tiles with less than 30 orders as there are not enough orders to trust the averages. Overall there is a pattern from with lower average ratings in the less densily populated areas in the north. We do however also have a state like Rio de Jainero that’s a bit of an outlier in that it’s densely populated and located in the center of the country but doesn’t have that high average ratings. And north of it, around the state of Minas Gerais there is also an “island” of quite high ratings compared to the surroundings. (The chart can be panned and zoomed using the controls shown when hovering the chart.) \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" From the previous analysis we’ve seen that there is a strong correlation between the reviews and the delivery time and delay. So let’s take a look at how these correlate geographically with the reviews. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"500!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/74.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Above we see the delivery time measured in days. What is immediately apparent is how the central area around São Paulo has the lowest delivery times and how the delivery time increases the further away we go from this area both north and south, although much more in the north. This corresponds very well with the pattern we saw in the ratings. We can also see that there is a part of Rio de Janeiro that has the longest delivery time in the area (the hexagon on the south-east corner in the state of Rio de Janeiro), this was also the hexagon with the lowest average review in the area – so overall there is a high correlation. From the previous analysis, however, we know that the delay also plays a big part in explaining the review scores, so let’s take a look at that. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"500!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/76.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" The delays don't show the same clear geographical pattern as we saw with the delivery time. The areas with higher delay seem more randomly scattered around the country. There does however seem to be a slight pattern of some of the areas with more delays being more towards the coast. It seems like the delivery time was able to explain the overall “global” pattern of reviews being better in the central area and gradually worsening especially towards the north, whereas the delays seem to be able to explain more the local differences in the reviews that don’t follow this overall “global” pattern. An example of this can be seen in the north-east corner near the city of Recife (use the controls found when hovering the chart to zoom in). Here there is one tile with an average review that’s considerably higher than the surrounding and it’s neighbor tile to the south-east, right next to it, has an average review, lower than the surroundings, so a very high local difference. When we look at the delay on the same two tiles, it looks like we have our explanation – the delay in the south-east neighboring tile is an outlier for the area and is considerably higher than the surrounding tiles. The same pattern can be seen for tiles all along the east-coast. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" So far, we’ve seen that most of the orders are (unsurprisingly) placed in the most densely populated areas. But also, we’ve also seen that there are more orders per inhabitant in the in the densely populated areas which is more surprising. Along with this we also see lower average reviews in the less dense areas, which could be an explanation for why there are fewer orders per inhabitant – the customer satisfaction is lower. So why are the customers less satisfied the in the less dense areas? From previously, we know that it’s closely connected with the delivery – its actual length and how much it was delayed. When looking at the geographical distribution of these parameters they do seem to be able to correlate very well with the patterns in average reviews we’ve observed. So let’s tie all this together by looking at, on a state-level, how the variables relate. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/78.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" To begin we’ll start by looking at how the adoption rate (measured in orders per inhabitant per state) relates to the average reviews in each state. It does look there is a tendency with states having a higher average review score also having a higher adoption rate (measured in orders per inhabitant). But the relation is not clear at all with a state like Rio de Janeiro being an example of a high adoption rate despite low average review scores and on the other end of the spectrum a state like Rondônia with a high review score but low adoption rate. But if we look at the group of the 8 states with the lowest average review scores, they all have very low adoption rate as well, except for Rio de Janeiro of course. To better understand these trends we can take a look at two of the best explaining variables we have available – the delivery time and the delays. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/80.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Looking at the delivery time we can see that the cities with the highest average review scores also have low delivery times and that cities with low reviews in general have higher delivery times. This chart also offers an explanation for why Rio de Janeiro was an outlier, in that it had a high adoption rate while having low average review scores. We can see here that Rio de Janeiro have quite low delivery times compared with the other low-review-score states, this could be part of the reason behind the high adoption rate. We can also see that a State like Rondonia, that had low adoption rate but high average review scores (the opposite of Rio de Janeiro) has high delivery times, which could explain why it has such low adoption rate. So, for both Rio de Janeiro and Rondonia, the delivery times offer explanations for their high and low adoption rates when seen in relation to the average review scores. Rio de Janeiro has low review scores so they should have a low adoption rate, but they don’t because they also have a short delivery time, and vise versa with Rondonia that has high average review scores, so they should have a high adoption rate, but don’t because of their long delivery times. So why then does Rondonia have a high average review score and Rio de Janeiro a low? Let’s look at the delays and see if that may help give us some insights. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/82.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Here, it’s seen how Rondana has low delays (the average delay is negative and y-axis showing the delays is flipped). This could offer some of the explanation as to why Rondana has so high average reviews. The case is not as clear with Rio de Janeiro however, that has delays similar to São Paulo. But São Paulo has much lower delivery times than Rio de Janeiro, so the relative underestimation of delivery time (negative average delay) is much higher compared to the length of the delivery times. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" To conclude we see that we have the highest adoption rates in urban areas and lowest in rural areas. We also have higher average review scores in urban areas compared to rural, so if we accept that we can use the average reviews scores as a proxy for the customer satisfaction, it makes sense that we have higher adoption rates where the customer satisfaction is high. We can also see that there is a good chance that much of this difference in customer satisfaction and hence adoption rates, has to do with the delivery. There is an overall pattern with high average review scores in the urban central part of the country and lower average review scores in the more rural areas in the north. This overall pattern can probably partly be explained by the delivery time that follows the same pattern with much longer delivery times in the north compared to the central part of the country. There are outliers however, that don’t follow this pattern between the delivery time and the average review scores, meaning that they can have a high delivery time but still have a high average review score, often these can, at least in part, be explained by the delays. So if an area has a high average review score and long delivery times it’s often because it also has large negative delays. There also seems to be a pattern where the adoption rate is mostly explained by the length of the delivery times whereas the review scores are more explained by the delay. So, if a state, unusually, has a high review score but a low adoption rate, it’s often because it has a long delivery time but also high negative delays (the items arrive faster than expected). This is for example the case for a state like Rondonia. This actually makes a lot of sense, as what the customer sees when making the decision about purchasing is the estimated delivery time (which is closely correlated with the delivery time) hence the high adoption/purchase rate in areas where this is low. Whereas the delay has more of an effect after the purchase has been made and therefore expresses itself in the average review score. Of course a delay also negatively effects the returning customer rate, so there are cross effect, but the dataset has a short time span and only shows a single purchase per customer, so we don’t see these. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" To test these hypotheses we can try to plot them as scatter plots, to more clearly see the relationships. To begin with we’ll look at the relationship between the delivery time and adoption rate in the below scatter plot. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/84.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" We can see that there actually is a very clear correlation between the log of the adoption rate and the delivery time. The plot is colored by the estimated delivery time, and as can be seen this correlates very well with the actual delivery time, and when it doesn’t, the actual delivery time seems to be the most influential on the adoption rate. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" The other hypothesis, that there is a strong correlation between the average reviews and the delay can also be visualized on a state basis using a scatter plot as seen below. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('iframe',{attrs:{\"id\":\"plot1\",\"width\":\"900\",\"height\":\"400!important\",\"frameborder\":\"0\",\"scrolling\":\"no\",\"src\":\"//plotly.com/~Ketelsen2/87.embed?showlink=false\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" Here it’s again evident that there indeed is a strong negative correlation between the average review score and the delay. The “band” of state going diagonally downward towards the lower right corner does have some width or leftover variance and it can be seen that this leftover variance is well explained by the delivery time that’s used for coloring the marks. An example is São Paulo, that is to the right of the diagonal, meaning that it has a higher rating than it’s delay dictates, looking at the delivery time however we can also see that this is unusually short. The opposite example can be found with the state of Para, that is placed to the left of the point cloud, meaning that it has a lower average review score than it’s delay would dictate, looking at the delivery time of Para we can see that it’s 23.2 days, which is also unusually high explaining the low raiting. So, to summarize the delay explains most of the review score and the delivery time explains much of the leftover variance. \")]),_c('h5',{staticClass:\"title is-5\"},[_vm._v(\"Predicting Ratings\")]),_c('div',{staticClass:\"block\"},[_vm._v(\" In this section, we will try to predict the review score of orders using machine learning. The objective is not to optimize performance but to derive which features actually helps the model the most, i.e. perform a feature importance analysis. We will use the features that appear to be correlated with the review score of an order based on the analysis in the previous sections. First, we needed to develop a model. In general, when predicting ordered classes, it is widely used to treat it as a regression task and then afterwards perform some sort of rounding on the prediction to get discrete classes, which is what we did. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" The model we’ll implement is a XXX, which is widely used for .. \")]),_c('div',{staticClass:\"block\"},[_vm._v(\" The model performance is satisfying as it outperforms the baseline model of predicting the majority class every time. However, the actual predictive model is not useful for Olist compared to the insigth or analyzing feature importance. The visualization below shows what features that are the most impactful on the predictions, i.e. affect the customer reviews the most according to our model. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('img',{attrs:{\"src\":require(\"./assets/shap_summary.png\"),\"alt\":\"Italian Trulli\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" From the plot above, it can be seen that the most impactful feature is actually the delay. Although delivery time is also an important factor for getting good customer reviews, it seems like the customers actually is more concerned with getting their package on time than the waiting time. According to the model, the product category has zero impact on the review score, but the other categorical feature, customer state, actually has some impact on the review score. The visualisation below gives a little more insight in terms of how the features affect the predicted review score. \")])])])]),_c('section',{staticClass:\"section has-no-padding shadow\"},[_c('div',{staticClass:\"container\"},[_c('img',{attrs:{\"src\":require(\"./assets/shap_summary2.png\"),\"alt\":\"Italian Trulli\"}})])]),_c('section',{staticClass:\"section\"},[_c('div',{staticClass:\"columns\"},[_c('div',{staticClass:\"column is-three-fifths is-offset-one-fifth\"},[_c('div',{staticClass:\"block\"},[_vm._v(\" The plot above indicates whether the feature's impact is either positive or negative and uses colors to show if the feature value was high or low. Looking at the most impactful feature, delays, it can be observed that when the delays value is high, it has a very negative effect on the predicted review score. The same goes with high delivery times. However, since delays are derived from the delivery time, delivery time will typically have a high value if delays have a high value. \")])])])]),_c('footer',{staticClass:\"footer\"},[_c('div',{staticClass:\"content has-text-centered\"},[_c('p',[_c('strong',[_vm._v(\"Bulma\")]),_vm._v(\" by \"),_c('a',{attrs:{\"href\":\"https://jgthms.com\"}},[_vm._v(\"Jeremy Thomas\")]),_vm._v(\". The source code is licensed \"),_c('a',{attrs:{\"href\":\"http://opensource.org/licenses/mit-license.php\"}},[_vm._v(\"MIT\")]),_vm._v(\". The website content is licensed \"),_c('a',{attrs:{\"href\":\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"}},[_vm._v(\"CC BY NC SA 4.0\")]),_vm._v(\". \")])])])])\n}]\n\nexport { render, staticRenderFns }","<template>\n  <div id=\"app\">\n    <section class=\"hero is-primary is-medium has-bg-img\">\n      <!-- Hero head: will stick at the top -->\n      <div class=\"hero-head\">\n        <nav class=\"navbar is-spaced\">\n          <div class=\"navbar-brand\">\n            <a class=\"navbar-item\">\n              <img src=\"./assets/logo-olist-white.png\" alt=\"Logo\">\n            </a>\n            <span class=\"navbar-burger\" data-target=\"navbarMenuHeroA\">\n              <span></span>\n              <span></span>\n              <span></span>\n            </span>\n          </div>\n          <div id=\"navbarMenuHeroA\" class=\"navbar-menu\">\n            <div class=\"navbar-end\">\n              <a class=\"navbar-item \">\n                Home\n              </a>\n              <a class=\"navbar-item\">\n                Examples\n              </a>\n              <a class=\"navbar-item\"\n                href=\"https://olist.com/pt-br/solucoes-para-comercio/vender-em-marketplaces/planos/\">\n                Plans\n              </a>\n              <span class=\"navbar-item\">\n                <a class=\"button is-primary is-inverted is-rounded\">\n\n                  <span>Explainer Notebook</span>\n                </a>\n              </span>\n            </div>\n          </div>\n        </nav>\n      </div>\n\n      <!-- Hero content: will be in the middle -->\n      <div class=\"hero-body\" style=\" padding-top: 5rem;padding-bottom: 9rem;\">\n        <div class=\"container has-text-centered\">\n          <div class=\"block\">\n            <p class=\"title\" style=\" padding-bottom: 2rem;\">\n              End-to-end solutions to sell online <br> without a headache\n            </p>\n          </div>\n          <div class=\"block\"></div>\n\n          <div class=\"block\">\n            <div class=\"columns is-1 is-variable\">\n              <div class=\"column\">\n                <button class=\"button is-outlined is-white is-fullwidth\">Product</button>\n              </div>\n              <div class=\"column\">\n                <button class=\"button is-outlined is-white is-fullwidth\"> <a href=\"deliveryTime\">Delivery Time</a>\n                </button>\n              </div>\n              <div class=\"column\">\n                <button class=\"button is-outlined is-white is-fullwidth \">Default</button>\n              </div>\n              <div class=\"column\">\n                <button class=\"button is-outlined is-white is-fullwidth\">Default</button>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n\n      <!-- Hero footer: will stick at the bottom -->\n      <div class=\"hero-foot\">\n\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n\n\n\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n          <div class=\"block\">\n            Olist knows that one of the keys to growth of the platform is to have a happy customer base that can act as\n            product ambassadors and stay on the platform while also spreading the word to new potential customers. They\n            have therefore asked us to provide some insights on how they are doing with regards to their customers and\n            if there is anything they can do to improve in this area. Luckily our dataset provides a good foundation for\n            exploring this topic as we have information about the customers, reviews, geography etc.\n\n\n          </div>\n          <div class=\"block\">\n            So, how do we actually know if the customers are happy? One of the ideal ways of knowing this, would be to\n            perform a customer survey, asking about the customers’ satisfaction after having gone through the purchasing\n            process. Olist, however, haven’t done this yet, so we’ll have to make use of a proxy. The best proxy,\n            available to us, is arguably the customer reviews. It’s not as direct of a measure of customer satisfaction\n            as a survey would have been, and one could argue that a review/rating is often more a reflection of the\n            quality of the product than the platform. Our argument here is that a review often reflects the entire\n            experience of a purchase – the product quality/price, delivery process, communication, and platform\n            satisfaction. And to have happy customers Olist not only needs to ensure the quality of the platform, but\n            every one of the aforementioned things.\n\n          </div>\n\n          <div class=\"block\">\n            So, to begin with let’s take a look at the average reviews over time. The reviews are given as a rating from\n            zero to five stars. We’ve excluded the months from before January 2017 in this plot as these didn’t have\n            enough reviews to provide an accurate of estimate of the average values.\n          </div>\n\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/6.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n          <div class=\"block\">\n            As we can see the reviews have remained relatively steady at a value of around 4.0 to 4.3 with a small dip\n            to around 3.7 around March 2018, but this dip has since then been recovered.\n\n          </div>\n          <div class=\"block\">\n            For Olist to improve their customer satisfaction, it would be good to understand what influences it, either\n            negatively or positively, so they can mitigate the negative factors and further improve on the positive\n            factors. A good starting point for such an analysis is to think about what factors could affect one’s own\n            satisfaction when making online purchases.\n\n          </div>\n          <div class=\"block\">\n            If we think about what affects a customer’s satisfaction we can take on a customer journey perspective. At\n            first the customer becomes aware of Olist. Here the branding influences the perceived quality of the\n            experience, then the customer uses the website to search for products they want or be inspired. In this\n            step, the quality of the website and the selection and presentation of products are the main factors. When\n            the customer enters a specific product page it’s important that the products are presented in an accurate\n            and descriptive way both in terms of the photos and text, to ensure that the product meets the expectations\n            based on the presentation at the product page.\n          </div>\n          <div class=\"block\">\n\n            When placing the order, the customer will of course pay for\n            the product, here the price will influence the satisfaction both in terms of the competitiveness of the\n            product price when compared to other websites/stores but also just in relation to the quality of the\n            product. The estimated arrival time of the package, usually given to the customer before placing the order,\n            will also affect whether or not the customer will actually go through with the purchase.\n            After placing the order, until receiving the item we have the delivery time. With regards to the\n            delivery time, two things are important. The absolute delivery time (longer delivery times are generally\n            worse) but also the actual delivery time compared to the estimated delivery time. As a long delivery time is\n            worse if you have been “promised” a short delivery time initially i.e. the package is delayed.\n          </div>\n          <div class=\"block\">\n\n            When the order finally arrives at the\n            customer, the state of the package is important as well as the service of the currier (Did the courier for\n            example leave the package at the doorstep as described?) When opening and using the product, the quality and\n            durability of the product are the main factors just as with the delivery time, we can assume that these are\n            also perceived in two ways – both in actual terms and relative to the expectations given to the customer by\n            the presentation on the website and the price. It’s ok to receive a cheap bike if that’s what you were\n            expecting and you didn’t pay too much either, it’s far worse if you paid more or somehow expected to get a\n            bargain from the presentation on the website.\n          </div>\n          <div class=\"block\">\n            Throughout the purchasing process communication is also a key factor but before, during and after the\n            purchasing\n            process. How good is the seller at answering inquiries? (We can’t see this directly, but maybe we\n            can use something else as an indicator).\n          </div>\n          <div class=\"block\">\n            So, to recap these are the factors that we imagine could be the most influential on the customer\n            satisfaction:\n            <div class=\"content\">\n              <ul>\n                <li>Olist branding </li>\n                <li>Website quality </li>\n                <li>Production selection and overview/search functionality </li>\n                <li>Product page accuracy and level of information – both in regards to photos and text </li>\n                <li>Price – relative to other sellers and quality of the product </li>\n                <li>Delivery time – both absolute and relative to the estimated delivery time </li>\n                <li>Delivery – state of package and service level of courier</li>\n                <li>Product quality – especially relative to expected quality and price </li>\n                <li>Communication</li>\n                <li>(add the customer himself, some people may be more likely to give low ratings)</li>\n              </ul>\n            </div>\n          </div>\n          <div class=\"block\">\n            This is quite a thorough list of factors that may influence the customer satisfaction. With the dataset\n            currently available to us it’s not possible to get an insight into all of these factors, but with a bit of\n            creativity we can get an indication of many of them.\n          </div>\n          <h5 class=\"title is-5\">PRODUCT QUALITY </h5>\n          <div class=\"block\">Let’s start by having a look at how the product affects the ratings. We will do so by\n            examining how much the reviews correlate with products. It’s of course worth mentioning that a correlation\n            here, as always, does not necessitate causality. It’s possible that one product has\n            significantly lower reviews than another product, not because of its quality, but because of other\n            correlated factors (confounding factors). For example, a product could have a high quality and a good price,\n            but always suffer from long delivery times and for that reason have low reviews. Another challenge here is\n            that it’s often easier to look at the correlation between two continuous variables, or in case one is\n            discrete, then only has a few discrete values. Here our discrete variable (product) has many possible\n            values. </div>\n\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"600!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/11.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n          <div class=\"block\">In the above plot we have shown the 95% confidence interval of the mean ratings of the\n            products with\n            more than 100 reviews. We've also renamed the products from their previous non-sensible product-IDs, to this\n            where the first part denotes the category of the given product and the second part denotes the ranking in\n            popularity of that product within its category. So \"health_beauty-1\", for example, would be the number one\n            (most popular) product within \"Health and Beauty\".\n\n          </div>\n\n          <div class=\"block\">\n            It’s evident that there is a significant difference in the reviews given to the worst\n            and the best products on this list as can be seen from the non-overlapping confidence intervals. It should\n            be\n            noted that selecting products with more than 100 reviews for this analysis in itself introduces a bias as\n            one could expect these products’ increased popularity to be caused in part by them having a higher average\n            rating than the average product and perhaps this is true, and the overall mean is probably skewed a bit\n            above the average 4.09 rating of the entire population of products, not by much, however. But the important\n            thing here is to note that there is indeed a significant difference across the rating of products,\n            indicating that (unsurprisingly) the product has an influence on the customer’s satisfaction.\n\n          </div>\n\n          <div class=\"block\">\n\n            For the rest of the analysis it would make sense to look at the other variables, such as the delivery time,\n            while holding the products\n            constant. That is, to look at how these other variables influences the average review score, for just one\n            product at a time, as that\n            would eliminate the variance coming from the product, which we can assume to be a big driver of the variance\n            in the average reviews scores.\n            This is, unfortunately, not possible as we don't have enough orders per product to conduct such an analysis,\n            so we'll have to look at the effect\n            of the other variables across all of the products.\n\n          </div>\n\n          <h5 class=\"title is-5\" id=\"deliveryTime\">Delivery Time</h5>\n\n          <div class=\"block\">\n            Another interesting thing to look at, is how the delivery time affects the rating. We would expect a\n            longer delivery time to have a negative impact on the rating and even more so if the informed estimated\n            delivery time was shorter than the actual i.e. a delay occurs.\n          </div>\n\n          <h6 class=\"title is-6\">Actual Delivery Time</h6>\n\n          <div class=\"block\">To begin with, we’ll look at how the actual delivery time is correlated with the ratings.\n            That is, how long does it take from the item is ordered until it arrives at the customer?</div>\n\n          <div class=\"block\">\n            Before that, however, we’ll have a look at the distribution of the delivery times as can be seen in the\n            below figure. It’s evident that most orders are delivered within zero to fifteen days with five to ten days\n            being the most normal delivery time. Only very few order have delivery times longer than 40 days.\n          </div>\n\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/13.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n\n          <div class=\"block\">\n\n            We’ll now proceed to see how the delivery relates to the ratings, one way to do this is to look at\n            intervals\n            of the actual delivery time and calculate the average review score for each of these intervals. When we do\n            this, we can see a strong correlation between these two variables, where a longer delivery time is\n            correlated with a lower average review. The plot only shows up until delivery times of 50 days as we have\n            excluded intervals with fewer than 500 observations to ensure that the average values are statistically\n            significant.(The bar over the tick mark \"0\" indicates the values between 0 and 2, and the bars are colored\n            by\n            the number of observations in that bin).\n\n\n          </div>\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/19.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n          <h6 class=\"title is-6\">Estimated Delivery Time</h6>\n\n          <div class=\"block\">\n            Another variable that may be of interest is the estimated delivery time i.e. the estimation presented to the\n            customer when placing the order. The hypothesis here being that customers are generally more satisfied\n            with\n            shorter estimated delivery times. We’ll start by looking at the distribution of the estimations. Here, we\n            see that the estimated delivery times af generally longer than the actual delivery time. This may be an\n            indication\n            of a deliberate policy by Olist of conservative/over-estimations, in order not to\n            disappoint the customers with delays. A deliberate overestimation of the delivery time so to speak. This, of\n            course has to\n            be balanced, as overestimations that are too big would make the customer less likely to go through with the\n            purchase.\n          </div>\n\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/21.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n\n            If we look at the relation between the delivery time estimations and the ratings as shown in the figure to\n            the right, we can again see a negative relation, indicating that customers are generally less satisfied\n            with\n            longer estimations. It does not seem to affect the average values as much, however, as the actual delivery\n            times. It’s also important to note that there is a high correlation between the actual and the estimated\n            delivery time, so the negative correlation between the estimated delivery time and the average review, may\n            just be because it generally also means that the actual delivery times are longer.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/90.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n\n\n          <h6 class=\"title is-6\">Delay</h6>\n\n          <div class=\"block\">\n            As we’ve seen so far, both the actual delivery times and estimated delivery times seem to be negatively\n            correlated with customer satisfaction. But it’s difficult to discern whether customers are actually less\n            satisfied when they get longer estimates or if it’s just because orders with longer estimates usually also\n            have longer actual delivery times where the actual delivery times in that case would act as what is known\n            as\n            a confounding variable.\n\n          </div>\n\n          <div class=\"block\">\n            To understand this relationship a bit better we can take a closer look at the interaction between these\n            three variables; estimated delivery time, actual delivery time and rating. The first thing that comes to\n            mind here is that the most important factor for customer satisfaction is actually the delay, calculated as\n            the difference between the estimated delivery time and actual delivery time. The thinking here being that\n            people would be more ok with a long delivery time if this is also what they expected, than if they\n            expected\n            a short delivery time. This thinking also follows the popular quote that happiness equals reality\n            minus\n            expectations. With happiness being the rating, reality being actual delivery time and expectations being\n            the\n            estimated delivery time. So let’s start by taking a look first at how the delays are distributed.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/29.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            As we’ve seen before the actual delivery times are generally longer than the estimated delivery times,\n            which\n            is also reflected by the above histogram, that shows that vast majority of orders are delivered before the\n            estimated delivery time, resulting in the distribution of the delay having a negative mean and mode\n            centered\n            around -11 days – meaning that packages on average arrive around 11 days before the given estimate.\n          </div>\n\n          <div class=\"block\">\n            We can also see how the delays relate to the customers rating by finding the average customer rating for\n            each interval of delay.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/31.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            It’s quite clear that something happens once the delay is positive (the order is delayed). Packages\n            without\n            delays have average review scores around or a bit above the overall the average of 4.08, whereas packages\n            with\n            delays quickly plummet to an average rating of around 1.5 – 1.8. It seems likely that the delay here is\n            the\n            cause of the decrease in ratings.\n          </div>\n\n          <div class=\"block\">\n            Something’s that’s missing so far is the relationship between all three variables. The delay does\n            implicitly\n            show all three variables being the residual between estimated and actual delivery time, but a delay of 5\n            days, can come from an initial estimation of 10 days or 50 days. And that may make a difference in how\n            that\n            delay is perceived by the customer. So to further investigate this relationship we will create a heatmap\n            showing the average rating as a function of the estimated and the actual delivery time. This plot also\n            implicitly shows the delay, as the diagonal elements are those where the estimated delivery time equals the\n            actual, and everything above the diagonal is negative delays (the package arrives before estimated\n            delivery\n            time) and below is positive delays.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"800!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/93.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            In the heatmap we can see the average review score as the color, where a high score is colored blue and a\n            low\n            is red. The most obvious pattern here is that everything above the diagonal (orders with a negative\n            delay) has a much higher rating than orders below the diagonal with a positive delay. Orders towards the\n            top\n            left corner (when both the actual and estimated delivery times are short) also have higher ratings than\n            orders towards the bottom right corner (when both the actual and estimated delivery times are high) in\n            spite\n            of these orders all being along the diagonal and hence not having a delay. So to sum up these findings,\n            customers care a lot about whether the order is delayed, but they also care about the length of the\n            delivery and are in general happier the shorter that is.\n          </div>\n\n          <div class=\"block\">\n            If we look at the top row, with orders having an actual delivery time between 0 and 2 days, we see that\n            customers are happier if the estimate was also low, than if the estimate was high, this is a bit\n            surprising as one could think they would be more positively surprised when the orders actual delivery time\n            is a lot lower than the estimated, but in fact the opposite is the case. This is good to know, as an\n            obvious tactic would be to just overestimate the delays\n            by far, to only have negative delays resulting in positive surprises, but this plot shows, that that’s not\n            the best solution also becasue, as previously mentioned, this would deter some from buying.\n            Customers are very unsatisfied with even small delays, but they are also somewhat\n            unsatisfied with negative delays and would not buy if estimate is too long. So, the right solution is\n            probably to provide an estimate that’s a bit on\n            the high side as the customer satisfaction punishment is higher for a underestimate than an overestimate,\n            but not too much on the high side as this is also punished, just not by as much. So there definitely is a\n            sweet spot to be found.\n          </div>\n\n          <h5 class=\"title is-5\">PRODUCT PRESENTATION</h5>\n\n          <div class=\"block\">\n            As previously mentioned, it can be speculated that the online presentation of the product can matter a lot\n            for the customer satisfaction. Both for the customer experience during the buying process, but also, and\n            perhaps more importantly, for the expectations. This is very analogous to the case just described with how\n            delivery times affects ratings. In that analysis we saw that the actual delivery time mattered for\n            the rating, but the delay (the difference between expectation and reality) mattered even more. The same\n            can be speculated to be the case for the product presentation, here the expectation does not come from an\n            estimated delivery time however, but instead from the online presentation and to some extension – the\n            price.\n          </div>\n\n          <div class=\"block\">\n            In the dataset available to us, the variables that best describe the level of description of products are\n            the number of photos for a specific product as well as the length of the description. We’ll start by\n            looking at how the number of photos relate to the average review scores.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/44.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            From the figure above it looks as if more photos generally are correlated with better reviews. As is\n            always the case the causation isn’t clear. It could be that better products generally have more photos, so\n            the difference in ratings is caused by this quality difference of the products, rather than the extra\n            information, leading to more realistic expectations provided by the photos themselves. But looking at this\n            figure alone, there are indications that it’s better to have more photos.\n          </div>\n\n          <div class=\"block\">\n            We can also look at the same plot for the text length divided into intervals.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/49.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            Again we can see a slight pattern with longer description lengths having higher average ratings. It should\n            be noted that the plot only shows a small part of the y-axis, so even though the differences look rather\n            large, it’s only from around 4.13 to 4.19, meaning very neglible differences compared to what we've\n            previously\n            seen with other variables such as the ones regarding the delivery.\n          </div>\n\n          <h5 class=\"title is-5\">Sellers</h5>\n\n          <div class=\"block\">\n            We’ve previously described how things such as communication and support may be important for the customer\n            experience. We don’t have any information on these values in the dataset, but we have some information\n            about the sellers, that could be used as proxies or indicators of the quality of the seller that may well\n            be correlated with the seller’s ability to serve the customers.\n          </div>\n\n          <div class=\"block\">\n            We’ll start by having a look at the sellers in terms of their size (measured by the number of orders they\n            have received) and how that size relates to average customer ratings they have received. What we can see is\n            that there actually is a very slight negative correlation between seller size and average ratings received.\n            But the correlation is very unclear. The main reason for this negative correlation is presumably that\n            sellers\n            with very few orders are more likely to only have received the most frequent review scores of 4 and 5,\n            whereas\n            the more experienced sellers will be more likely to also have received the less frequent lower scores,\n            bringing\n            them down to something closer to the global average review score.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/58.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <h5 class=\"title is-5\">Customers</h5>\n\n          <div class=\"block\">\n            Another thing that may be of influence to the reviews received are the customers. Some customers may be more\n            or less inclined to give a good or a bad review, depending on things like their personality,\n            socio-demographic status, how they’re treated by the company etc. Presumably one of the most important\n            things\n            would be the personal bias i.e. that some people tend to be either more positive or negative in their\n            reviews. If we knew the personal bias, this could be used to adjust for it, when analyzing the reviews given\n            by a certain customer. If one customer always gave reviews between 1-4 stars for example, it could be that\n            he perceived 4 as being a very good score and that a rating of 5 was only something to be given under very\n            rare circumstances. Another customer may only give scores between 4 and 5, where 5 would be the standard\n            and 4 was only if there was something specifically wrong with the item. Hence, we could introduce a personal\n            standardized scale where the first person’s rating of 4 would be more or less equivalent to the second\n            person’s rating of 5. This would be ideal, we can’t however do this as we only have access to one order per\n            customer in the dataset.\n          </div>\n\n          <div class=\"block\">\n            But let’s start the analysis of the customers by looking at the geographical location of our customers. We\n            will do so using a choropleth map, where the count of orders is aggregated on a state level.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <img src=\"./assets/customers1.png\" alt=\"Italian Trulli\">\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            It’s evident that the vast majority of orders come from the states around São Paulo and Rio de Janeiro – the\n            two largest cities in Brazil. Out of the 93k individual orders 62k come from the just the three states with\n            most orders as can also be seen from the bar chart below.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/69.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            In the bar chart above the population has also been shown alongside the number of orders for each of the\n            states. It can be seen that the most populated state São Paulo, which is also the state of Brazil’s largest\n            city by the same name also has the highest order count when seen relative to its population size. This means\n            that the platform is more popular (measured by orders per inhabitant) than in the other smaller states. It\n            makes sense that more metropolitan areas are earlier adopters of a technology based platform like this, on\n            the other hand people in more rural areas may benefit more from shopping online, with fewer shops available.\n            On the other, other hand delivery price and time is likely higher for these people, which could also explain\n            their smaller adoption.\n          </div>\n\n          <div class=\"block\">\n            Now that we know approximately where our customers are located we can proceed to look at how our main\n            variable of interest – the review score – is distributed geographically amongst the customers.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"500!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/71.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            We’ve now changed to a different type of geographical plot known as a hexagonal tile map. This allows us to\n            perform our aggregations over evenly sized areas and at a smaller level than the states to also see regional\n            differences within the states. The hexagonals does not cover all of Brazil, this is because we’ve chosen to\n            exclude tiles with less than 30 orders as there are not enough orders to trust the averages. Overall there\n            is a pattern from with lower average ratings in the less densily populated areas in the north. We do however\n            also have a state like Rio de Jainero that’s a bit of an outlier in that it’s densely populated and located\n            in the center of the country but doesn’t have that high average ratings. And north of it, around the state\n            of Minas Gerais there is also an “island” of quite high ratings compared to the surroundings. (The chart can\n            be panned and zoomed using the controls shown when hovering the chart.)\n          </div>\n\n          <div class=\"block\">\n            From the previous analysis we’ve seen that there is a strong correlation between the reviews and the\n            delivery time and delay. So let’s take a look at how these correlate geographically with the reviews.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"500!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/74.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            Above we see the delivery time measured in days. What is immediately apparent is how the central area around\n            São Paulo has the lowest delivery times and how the delivery time increases the further away we go from this\n            area both north and south, although much more in the north. This corresponds very well with the pattern we\n            saw in the ratings. We can also see that there is a part of Rio de Janeiro that has the longest delivery\n            time in the area (the hexagon on the south-east corner in the state of Rio de Janeiro), this was also the\n            hexagon with the lowest average\n            review in the area – so overall there is a high correlation. From the previous analysis, however, we know\n            that the delay also plays a big part in explaining the review scores, so let’s take a look at that.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"500!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/76.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            The delays don't show the same clear geographical pattern as we saw with the delivery time. The areas\n            with higher delay seem more randomly scattered around the country. There does however seem to be a slight\n            pattern of some of the areas with more delays being more towards the coast. It seems like the delivery time\n            was able to explain the overall “global” pattern of reviews being better in the central area and gradually\n            worsening\n            especially towards the north, whereas the delays seem to be able to explain more the local differences in\n            the reviews that don’t follow this overall “global” pattern. An example of this can be seen in the\n            north-east corner near the city of Recife (use the controls found when hovering the chart to zoom in). Here\n            there is one tile with an\n            average review that’s considerably higher than the surrounding and it’s neighbor tile to the south-east,\n            right next to it, has an average review, lower than the surroundings, so a very high local difference. When\n            we look at the delay on the same two tiles, it looks like we have our explanation – the delay in the\n            south-east neighboring tile is an outlier for the area and is considerably higher than the surrounding\n            tiles. The same pattern can be seen for tiles all along the east-coast.\n          </div>\n\n          <div class=\"block\">\n            So far, we’ve seen that most of the orders are (unsurprisingly) placed in the most densely populated areas.\n            But also, we’ve also seen that there are more orders per inhabitant in the in the densely populated areas\n            which is more surprising. Along with this we also see lower average reviews in the less dense areas, which\n            could be an explanation for why there are fewer orders per inhabitant – the customer satisfaction is lower.\n            So why are the customers less satisfied the in the less dense areas? From previously, we know that it’s\n            closely connected with the delivery – its actual length and how much it was delayed. When looking at the\n            geographical distribution of these parameters they do seem to be able to correlate very well with the\n            patterns in average reviews we’ve observed. So let’s tie all this together by looking at, on a state-level,\n            how the variables relate.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/78.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            To begin we’ll start by looking at how the adoption rate (measured in orders per inhabitant per state)\n            relates\n            to the average reviews in each state. It\n            does look there is a tendency with states having a higher average review score also having a higher adoption\n            rate (measured in orders per inhabitant). But the relation is not clear at all with a state like Rio de\n            Janeiro being an example of a high adoption rate despite low average review scores and on the other end of\n            the spectrum a state like Rondônia with a high review score but low adoption rate. But if we look at the\n            group of the 8 states with the lowest average review scores, they all have very low adoption rate as well,\n            except for Rio de Janeiro of course. To better understand these trends we can take a look at two of the best\n            explaining variables we have available – the delivery time and the delays.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/80.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n          <div class=\"block\">\n            Looking at the delivery time we can see that the cities with the highest average review scores also have low\n            delivery times and that cities with low reviews in general have higher delivery times. This chart also\n            offers an explanation for why Rio de Janeiro was an outlier, in that it had a high adoption rate while\n            having low average review scores. We can see here that Rio de Janeiro have quite low delivery times compared\n            with the other low-review-score states, this could be part of the reason behind the high adoption rate. We can\n            also see that a State like Rondonia, that had low adoption rate but high average review scores (the opposite\n            of Rio de Janeiro) has high delivery times, which could explain why it has such low adoption rate. So, for\n            both Rio de Janeiro and Rondonia, the delivery times offer explanations for their high and low adoption\n            rates when seen in relation to the average review scores. Rio de Janeiro has low review scores so they\n            should have a low adoption rate, but they don’t because they also have a short delivery time, and vise versa\n            with Rondonia that has high average review scores, so they should have a high adoption rate, but don’t\n            because of their long delivery times. So why then does Rondonia have a high average review score and Rio de\n            Janeiro a low? Let’s look at the delays and see if that may help give us some insights.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/82.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            Here, it’s seen how Rondana has low delays (the average delay is negative and y-axis showing the delays is\n            flipped). This could offer some of the explanation as to why Rondana has so high average reviews. The case\n            is not as clear with Rio de Janeiro however, that has delays similar to São Paulo. But São Paulo has much\n            lower delivery times than Rio de Janeiro, so the relative underestimation of delivery time (negative average\n            delay) is much higher compared to the length of the delivery times.\n          </div>\n\n          <div class=\"block\">\n            To conclude we see that we have the highest adoption rates in urban areas and lowest in rural areas. We also\n            have higher average review scores in urban areas compared to rural, so if we accept that we can use the\n            average reviews scores as a proxy for the customer satisfaction, it makes sense that we have higher adoption\n            rates where the customer satisfaction is high. We can also see that there is a good chance that much of this\n            difference in customer satisfaction and hence adoption rates, has to do with the delivery. There is an\n            overall pattern with high average review scores in the urban central part of the country and lower average\n            review scores in the more rural areas in the north. This overall pattern can probably partly be explained by\n            the delivery time that follows the same pattern with much longer delivery times in the north compared to the\n            central part of the country. There are outliers however, that don’t follow this pattern between the delivery\n            time and the average review scores, meaning that they can have a high delivery time but still have a high\n            average review score, often these can, at least in part, be explained by the delays. So if an area has a\n            high average review score and long delivery times it’s often because it also has large negative delays.\n            There also seems to be a pattern where the adoption rate is mostly explained by the length of the\n            delivery times whereas the review scores are more explained by the delay. So, if a state, unusually, has a\n            high review score but a low adoption rate, it’s often because it has a long delivery time but also high\n            negative delays (the items arrive faster than expected). This is for example the case for a state like\n            Rondonia. This actually makes a lot of sense, as what the customer sees when making the decision about\n            purchasing is the estimated delivery time (which is closely correlated with the delivery time) hence the\n            high adoption/purchase rate in areas where this is low. Whereas the delay has more of an effect after the\n            purchase has been made and therefore expresses itself in the average review score. Of course a delay also\n            negatively effects the returning customer rate, so there are cross effect, but the dataset has a short time\n            span and only shows a single purchase per customer, so we don’t see these.\n          </div>\n\n          <div class=\"block\">\n            To test these hypotheses we can try to plot them as scatter plots, to more clearly see the relationships. To\n            begin with we’ll look at the relationship between the delivery time and adoption rate in the below scatter\n            plot.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/84.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            We can see that there actually is a very clear correlation between the log of the adoption rate and the\n            delivery time. The plot is colored by the estimated delivery time, and as can be seen this correlates very\n            well with the actual delivery time, and when it doesn’t, the actual delivery time seems to be the most\n            influential on the adoption rate.\n          </div>\n\n          <div class=\"block\">\n            The other hypothesis, that there is a strong correlation between the average reviews and the delay can also\n            be visualized on a state basis using a scatter plot as seen below.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <iframe id=\"plot1\" width=\"900\" height=\"400!important\" frameborder=\"0\" scrolling=\"no\"\n          src=\"//plotly.com/~Ketelsen2/87.embed?showlink=false\"></iframe>\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n          <div class=\"block\">\n            Here it’s again evident that there indeed is a strong negative correlation between the average review score\n            and the delay. The “band” of state going diagonally downward towards the lower right corner does have some\n            width or leftover variance and it can be seen that this leftover variance is well explained by the delivery\n            time that’s used for coloring the marks. An example is São Paulo, that is to the right of the diagonal,\n            meaning that it has a higher rating than it’s delay dictates, looking at the delivery time however we can\n            also see that this is unusually short. The opposite example can be found with the state of Para, that is\n            placed to the left of the point cloud, meaning that it has a lower average review score than it’s delay\n            would dictate, looking at the delivery time of Para we can see that it’s 23.2 days, which is also unusually\n            high explaining the low raiting. So, to summarize the delay explains most of the review score and the\n            delivery time explains much of the leftover variance.\n          </div>\n\n\n\n\n          <h5 class=\"title is-5\">Predicting Ratings</h5>\n\n          <div class=\"block\">\n            In this section, we will try to predict the review score of orders using machine learning. The objective is\n            not to optimize performance but to derive which features actually helps the model the most, i.e. perform a\n            feature importance analysis. We will use the features that appear to be correlated with the review score of\n            an order based on the analysis in the previous sections. First, we needed to develop a model. In general,\n            when predicting ordered classes, it is widely used to treat it as a regression task and then afterwards\n            perform some sort of rounding on the prediction to get discrete classes, which is what we did.\n          </div>\n\n          <div class=\"block\">\n            The model we’ll implement is a XXX, which is widely used for ..\n          </div>\n\n          <div class=\"block\">\n            The model performance is satisfying as it outperforms the baseline model of predicting the majority class\n            every time. However, the actual predictive model is not useful for Olist compared to the insigth or\n            analyzing feature importance. The visualization below shows what features that are the most impactful on the\n            predictions, i.e. affect the customer reviews the most according to our model.\n          </div>\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <img src=\"./assets/shap_summary.png\" alt=\"Italian Trulli\">\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n\n          <div class=\"block\">\n            From the plot above, it can be seen that the most impactful feature is actually the delay. Although delivery\n            time is also an important factor for getting good customer reviews, it seems like the customers actually is\n            more concerned with getting their package on time than the waiting time. According to the model, the product\n            category has zero impact on the review score, but the other categorical feature, customer state, actually\n            has some impact on the review score. The visualisation below gives a little more insight in terms of how the\n            features affect the predicted review score.\n          </div>\n\n\n        </div>\n      </div>\n    </section>\n\n\n    <section class=\"section has-no-padding shadow\">\n      <div class=\"container\">\n        <img src=\"./assets/shap_summary2.png\" alt=\"Italian Trulli\">\n      </div>\n    </section>\n\n\n    <section class=\"section\">\n      <div class=\"columns\">\n        <div class=\"column is-three-fifths is-offset-one-fifth\">\n\n          <div class=\"block\">\n            The plot above indicates whether the feature's impact is either positive or negative and uses colors to show\n            if the feature value was high or low. Looking at the most impactful feature, delays, it can be observed that\n            when the delays value is high, it has a very negative effect on the predicted review score. The same goes\n            with high delivery times. However, since delays are derived from the delivery time, delivery time will\n            typically have a high value if delays have a high value.\n          </div>\n\n\n\n        </div>\n      </div>\n    </section>\n\n\n\n\n\n    <footer class=\"footer\">\n      <div class=\"content has-text-centered\">\n        <p>\n          <strong>Bulma</strong> by <a href=\"https://jgthms.com\">Jeremy Thomas</a>. The source code is licensed\n          <a href=\"http://opensource.org/licenses/mit-license.php\">MIT</a>. The website content\n          is licensed <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">CC BY NC SA 4.0</a>.\n        </p>\n      </div>\n    </footer>\n\n  </div>\n</template>\n\n<script>\n\nexport default {\n  name: 'App',\n  components: {\n\n  }\n}\n</script>\n\n<style>\n#app {\n  font-family: Avenir, Helvetica, Arial, sans-serif;\n  /*-webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  text-align: center;\n  color: #2c3e50;\n  */\n}\n\n.button {\n  border-radius: 40;\n}\n\n.shadow {\n  -moz-box-shadow: inset 0 0 10px #000000;\n  -webkit-box-shadow: inset 0 0 10px #000000;\n  box-shadow: inset 0px 11px 8px -10px rgb(235, 235, 235),\n    inset 0px -11px 8px -10px rgb(235, 235, 235);\n}\n\n.has-bg-img {\n  background: url('assets/Frame1.png')center center;\n  background-size: cover;\n}\n</style>\n","import mod from \"-!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js??clonedRuleSet-40.use[1]!../node_modules/@vue/vue-loader-v15/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./App.vue?vue&type=template&id=9211a33e&\"\nimport script from \"./App.vue?vue&type=script&lang=js&\"\nexport * from \"./App.vue?vue&type=script&lang=js&\"\nimport style0 from \"./App.vue?vue&type=style&index=0&id=9211a33e&prod&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../node_modules/@vue/vue-loader-v15/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","import Vue from 'vue'\nimport App from './App.vue'\nrequire('@/assets/main.scss');\n\nVue.config.productionTip = false\n\nnew Vue({\n  render: h => h(App),\n}).$mount('#app')\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/\";","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t143: 0\n};\n\n// no chunk on demand loading\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n__webpack_require__.O.j = function(chunkId) { return installedChunks[chunkId] === 0; };\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\treturn __webpack_require__.O(result);\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkfinal_project\"] = self[\"webpackChunkfinal_project\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [998], function() { return __webpack_require__(9166); })\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n"],"names":["render","_vm","this","_self","_c","_m","staticRenderFns","attrs","staticClass","require","_v","staticStyle","name","components","component","Vue","h","App","$mount","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","undefined","exports","module","__webpack_modules__","m","deferred","O","result","chunkIds","fn","priority","notFulfilled","Infinity","i","length","fulfilled","j","Object","keys","every","key","splice","r","n","getter","__esModule","d","a","definition","o","defineProperty","enumerable","get","g","globalThis","Function","e","window","obj","prop","prototype","hasOwnProperty","call","Symbol","toStringTag","value","p","installedChunks","chunkId","webpackJsonpCallback","parentChunkLoadingFunction","data","moreModules","runtime","some","id","chunkLoadingGlobal","self","forEach","bind","push","__webpack_exports__"],"sourceRoot":""}